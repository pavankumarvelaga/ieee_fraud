{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "import bokeh as bh\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from glob import glob\n",
    "import re\n",
    "from math import ceil\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold,KFold,StratifiedKFold,train_test_split\n",
    "import random\n",
    "import operator\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import fastai.tabular as ft\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('train_identity.csv')\n",
    "train_trans = pd.read_csv('train_transaction.csv')\n",
    "train_df = train_trans.merge(train_id,how='left',on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = pd.read_csv('test_identity.csv')\n",
    "test_trans = pd.read_csv('test_transaction.csv')\n",
    "test_df = test_trans.merge(test_id,how='left',on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_id,train_trans,test_id,test_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aim.com',\n",
       " 'anonymous.com',\n",
       " 'aol.com',\n",
       " 'att.net',\n",
       " 'bellsouth.net',\n",
       " 'cableone.net',\n",
       " 'centurylink.net',\n",
       " 'cfl.rr.com',\n",
       " 'charter.net',\n",
       " 'comcast.net',\n",
       " 'cox.net',\n",
       " 'earthlink.net',\n",
       " 'embarqmail.com',\n",
       " 'frontier.com',\n",
       " 'frontiernet.net',\n",
       " 'gmail',\n",
       " 'gmail.com',\n",
       " 'gmx.de',\n",
       " 'hotmail.co.uk',\n",
       " 'hotmail.com',\n",
       " 'hotmail.de',\n",
       " 'hotmail.es',\n",
       " 'hotmail.fr',\n",
       " 'icloud.com',\n",
       " 'juno.com',\n",
       " 'live.com',\n",
       " 'live.com.mx',\n",
       " 'live.fr',\n",
       " 'mac.com',\n",
       " 'mail.com',\n",
       " 'me.com',\n",
       " 'msn.com',\n",
       " nan,\n",
       " 'netzero.com',\n",
       " 'netzero.net',\n",
       " 'optonline.net',\n",
       " 'outlook.com',\n",
       " 'outlook.es',\n",
       " 'prodigy.net.mx',\n",
       " 'protonmail.com',\n",
       " 'ptd.net',\n",
       " 'q.com',\n",
       " 'roadrunner.com',\n",
       " 'rocketmail.com',\n",
       " 'sbcglobal.net',\n",
       " 'sc.rr.com',\n",
       " 'servicios-ta.com',\n",
       " 'suddenlink.net',\n",
       " 'twc.com',\n",
       " 'verizon.net',\n",
       " 'web.de',\n",
       " 'windstream.net',\n",
       " 'yahoo.co.jp',\n",
       " 'yahoo.co.uk',\n",
       " 'yahoo.com',\n",
       " 'yahoo.com.mx',\n",
       " 'yahoo.de',\n",
       " 'yahoo.es',\n",
       " 'yahoo.fr',\n",
       " 'ymail.com'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "set(train_df['P_emaildomain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum',\n",
    "          'scranton.edu': 'other', 'netzero.net': 'other',\n",
    "          'optonline.net': 'other', 'comcast.net': 'other', \n",
    "          'cfl.rr.com': 'other', 'sc.rr.com': 'other',\n",
    "          'suddenlink.net': 'other', 'windstream.net': 'other',\n",
    "          'gmx.de': 'other', 'earthlink.net': 'other', \n",
    "          'servicios-ta.com': 'other', 'bellsouth.net': 'other', \n",
    "          'web.de': 'other', 'mail.com': 'other',\n",
    "          'cableone.net': 'other', 'roadrunner.com': 'other', \n",
    "          'protonmail.com': 'other', 'anonymous.com': 'other',\n",
    "          'juno.com': 'other', 'ptd.net': 'other',\n",
    "          'netzero.com': 'other', 'cox.net': 'other', \n",
    "          'hotmail.co.uk': 'microsoft', \n",
    "          'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', \n",
    "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', \n",
    "          'live.com': 'microsoft', 'aim.com': 'aol',\n",
    "          'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n",
    "          'gmail.com': 'google', 'me.com': 'apple', \n",
    "          'hotmail.com': 'microsoft',  \n",
    "          'hotmail.fr': 'microsoft',\n",
    "          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', \n",
    "          'yahoo.de': 'yahoo', \n",
    "          'live.fr': 'microsoft', 'verizon.net': 'yahoo', \n",
    "          'msn.com': 'microsoft', 'q.com': 'centurylink',\n",
    "          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', \n",
    "           'rocketmail.com': 'yahoo', \n",
    "          'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n",
    "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', \n",
    "          'embarqmail.com': 'centurylink', \n",
    "          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo',\n",
    "          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft',\n",
    "           'aol.com': 'aol', 'icloud.com': 'apple'}\n",
    "\n",
    "us_emails = ['gmail', 'net', 'edu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    train_df[c + '_bin'] = train_df[c].map(emails)\n",
    "    test_df[c + '_bin'] = test_df[c].map(emails)\n",
    "    \n",
    "    train_df[c + '_suffix'] = train_df[c].map(lambda x: str(x).split('.')[-1])\n",
    "    test_df[c + '_suffix'] = test_df[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    train_df[c + '_suffix'] = train_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    test_df[c + '_suffix'] = test_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Trans_min_mean'] = train_df['TransactionAmt'] - train_df['TransactionAmt'].mean()\n",
    "train_df['Trans_min_std'] = train_df['Trans_min_mean'] / train_df['TransactionAmt'].std()\n",
    "test_df['Trans_min_mean'] = test_df['TransactionAmt'] - test_df['TransactionAmt'].mean()\n",
    "test_df['Trans_min_std'] = test_df['Trans_min_mean'] / test_df['TransactionAmt'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_to_mean_card_id'] = train_df['TransactionAmt'] - train_df.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_std_card_id'] = train_df['TransactionAmt_to_mean_card_id'] / train_df.groupby(['Card_ID'])['TransactionAmt'].transform('std')\n",
    "test_df['TransactionAmt_to_mean_card_id'] = test_df['TransactionAmt'] - test_df.groupby(['Card_ID'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_std_card_id'] = test_df['TransactionAmt_to_mean_card_id'] / test_df.groupby(['Card_ID'])['TransactionAmt'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_to_mean_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_mean_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_std_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train_df['TransactionAmt_to_std_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test_df['TransactionAmt_to_mean_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_mean_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_std_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test_df['TransactionAmt_to_std_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['first_value_card1'] = df_train['card1'].astype(str).str[0:1].astype(float)\n",
    "train_df['two_value_card1'] = df_train['card1'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "test_df['first_value_card1'] = test_df['card1'].astype(str).str[0:1].astype(float)\n",
    "test_df['two_value_card1'] = test_df['card1'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "train_df['card2'] = train_df['card2'].fillna(0)\n",
    "train_df['first_value_card2'] = train_df['card2'].astype(str).str[0:1].astype(float)\n",
    "train_df['two_value_card2'] = train_df['card2'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "test_df['card2'] = test_df['card2'].fillna(0)\n",
    "test_df['first_value_card2'] = test_df['card2'].astype(str).str[0:1].astype(float)\n",
    "test_df['two_value_card2'] = test_df['card2'].astype(str).str[0:2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train_df.columns)\n",
    "for i in ['isFraud','TransactionDT']:\n",
    "    cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mv = missing_data(train_df)\n",
    "test_mv = missing_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total       470255\n",
       "Percent     92.809\n",
       "Types      float64\n",
       "Name: dist2, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mv['dist2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_exp_lst = []\n",
    "for i in cols:\n",
    "    if train_mv[i]['Percent'] > 90 and test_mv[i]['Percent'] >90:\n",
    "        col_exp_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col_exp_lst:\n",
    "    cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_decimal'] = ((train_df['TransactionAmt'] - train_df['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test_df['TransactionAmt_decimal'] = ((test_df['TransactionAmt'] - test_df['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "# Count encoding for card1 feature. \n",
    "# Explained in this kernel: https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\n",
    "train_df['card1_count_full'] = train_df['card1'].map(pd.concat([train_df['card1'], test_df['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "test_df['card1_count_full'] = test_df['card1'].map(pd.concat([train_df['card1'], test_df['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-feature\n",
    "train_df['Transaction_day_of_week'] = np.floor((train_df['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "test_df['Transaction_day_of_week'] = np.floor((test_df['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "train_df['Transaction_hour'] = np.floor(train_df['TransactionDT'] / 3600) % 24\n",
    "test_df['Transaction_hour'] = np.floor(test_df['TransactionDT'] / 3600) % 24\n",
    "\n",
    "# Some arbitrary features interaction\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train_df[feature] = train_df[f1].astype(str) + '_' + train_df[f2].astype(str)\n",
    "    test_df[feature] = test_df[f1].astype(str) + '_' + test_df[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train_df[feature].astype(str).values) + list(test_df[feature].astype(str).values))\n",
    "    train_df[feature] = le.transform(list(train_df[feature].astype(str).values))\n",
    "    test_df[feature] = le.transform(list(test_df[feature].astype(str).values))\n",
    "    \n",
    "for feature in ['id_34', 'id_36']:\n",
    "    if feature in cols:\n",
    "        # Count encoded for both train and test\n",
    "        train_df[feature + '_count_full'] = train_df[feature].map(pd.concat([train_df[feature], test_df[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        test_df[feature + '_count_full'] = test_df[feature].map(pd.concat([train_df[feature], test_df[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        \n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n",
    "    if feature in cols:\n",
    "        # Count encoded separately for train and test\n",
    "        train_df[feature + '_count_dist'] = train_df[feature].map(train_df[feature].value_counts(dropna=False))\n",
    "        test_df[feature + '_count_dist'] = test_df[feature].map(test_df[feature].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df['TransactionDT'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan2mean(df):\n",
    "    for x in list(df.columns.values):\n",
    "        #print(\"___________________\"+x)\n",
    "        #print(df[x].isna().sum())\n",
    "        if df[x]\n",
    "        df[x] = df[x].fillna(df[x].mean())\n",
    "       #print(\"Mean-\"+str(df[x].mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df=nan2mean(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df=nan2mean(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist2\n",
      "id_07\n",
      "id_08\n",
      "id_21\n",
      "id_22\n",
      "id_23\n",
      "id_24\n",
      "id_25\n",
      "id_26\n",
      "id_27\n",
      "isFraud\n",
      "TransactionDT\n"
     ]
    }
   ],
   "source": [
    "cols_for_model = list(train_df.columns)\n",
    "col_exp_lst.extend(['isFraud','TransactionDT'])\n",
    "for i in col_exp_lst:\n",
    "    print(i)\n",
    "    cols_for_model.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD-object\n",
      "card4-object\n",
      "card6-object\n",
      "P_emaildomain-object\n",
      "R_emaildomain-object\n",
      "M1-object\n",
      "M2-object\n",
      "M3-object\n",
      "M4-object\n",
      "M5-object\n",
      "M6-object\n",
      "M7-object\n",
      "M8-object\n",
      "M9-object\n",
      "id_12-object\n",
      "id_15-object\n",
      "id_16-object\n",
      "id_28-object\n",
      "id_29-object\n",
      "id_30-object\n",
      "id_31-object\n",
      "id_33-object\n",
      "id_34-object\n",
      "id_35-object\n",
      "id_36-object\n",
      "id_37-object\n",
      "id_38-object\n",
      "DeviceType-object\n",
      "DeviceInfo-object\n"
     ]
    }
   ],
   "source": [
    "for f in cols_for_model:\n",
    "    if train_df[f].dtype=='object':\n",
    "        print(f+\"-\"+str(train_df[f].dtype))\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        test_df[f] = lbl.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_df = train_df[train_df['TransactionDT'] < 13800000].reset_index()\n",
    "# val_df = train_df[train_df['TransactionDT'] >= 13800000].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsMeter():    \n",
    "    def __init__(self, y_true, y_pred, threshold):\n",
    "        self.y_true = y_true        \n",
    "        self.y_pred = y_pred        \n",
    "        self.thresh = threshold            \n",
    "    \n",
    "    def fit(self):        \n",
    "        metrics = {}        \n",
    "        metrics['auc'] = roc_auc_score(self.y_true, self.y_pred)                \n",
    "        self.y_pred = [1 if x > self.thresh else 0 for x in self.y_pred]        \n",
    "        metrics['f1'] = f1_score(self.y_true, self.y_pred,average = 'macro')        \n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_true, self.y_pred).ravel()                \n",
    "        metrics['sensitivity/recall'] = tp / (tp+fn)\n",
    "        metrics['precision'] = tp / (tp+fp)\n",
    "        metrics[\"accuracy\"] = (tp + tn) / (tp + fp + fn + tn)\n",
    "        metrics['specificity'] = tn / (tn+fp)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunXGB(x_build,x_val,y_build,y_val,dtest,seed):\n",
    "    dbuild = xgb.DMatrix(x_build,y_build)\n",
    "    dval = xgb.DMatrix(x_val,y_val)\n",
    "    watchlist = [(dbuild, 'train'), (dval, 'val')]\n",
    "    params = {'objective': 'binary:logistic',\n",
    "              'booster': 'gbtree',\n",
    "              'eval_metric': 'auc',\n",
    "              'nthread': 96,\n",
    "              'max_depth': 6,\n",
    "              #'learning_rate': 0.009\n",
    "              'subsample': 0.8,\n",
    "              'min_child_weight': 1,\n",
    "              \"colsample_bytree\": 0.9,\n",
    "              'eta': 0.08,\n",
    "              'verbose_eval': True,\n",
    "              'silent':1,\n",
    "              'seed': seed\n",
    "              }\n",
    "    clf_xgb = xgb.train(params, dbuild, num_boost_round=2000, verbose_eval=50, early_stopping_rounds=30, evals=watchlist)\n",
    "    pred_val = clf_xgb.predict(dval, ntree_limit=clf_xgb.best_iteration)\n",
    "    pred_t = clf_xgb.predict(dtest, ntree_limit=clf_xgb.best_iteration)\n",
    "    return(clf_xgb,pred_val,pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1,pred_v1,pred_t1 = RunXGB(build_df[cols].iloc[:],val_df[cols].iloc[:],\n",
    "# build_df['isFraud'].iloc[:],val_df['isFraud'].iloc[:]),seed = 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.reset_index(drop =True)\n",
    "x_train = train[cols_for_model]\n",
    "y_train = train['isFraud']\n",
    "dtest = xgb.DMatrix(test_df[cols_for_model].iloc[:])\n",
    "td = test_df['TransactionID'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1648"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavan/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.790447\tval-auc:0.792069\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.902252\tval-auc:0.895724\n",
      "[100]\ttrain-auc:0.929282\tval-auc:0.919691\n",
      "[150]\ttrain-auc:0.941395\tval-auc:0.929623\n",
      "[200]\ttrain-auc:0.949652\tval-auc:0.935695\n",
      "[250]\ttrain-auc:0.955857\tval-auc:0.940212\n",
      "[300]\ttrain-auc:0.961473\tval-auc:0.944142\n",
      "[350]\ttrain-auc:0.965689\tval-auc:0.94728\n",
      "[400]\ttrain-auc:0.969462\tval-auc:0.949776\n",
      "[450]\ttrain-auc:0.973024\tval-auc:0.952158\n",
      "[500]\ttrain-auc:0.976025\tval-auc:0.954421\n",
      "[550]\ttrain-auc:0.978245\tval-auc:0.955998\n",
      "[600]\ttrain-auc:0.980407\tval-auc:0.957334\n",
      "[650]\ttrain-auc:0.98212\tval-auc:0.95852\n",
      "[700]\ttrain-auc:0.983903\tval-auc:0.959865\n",
      "[750]\ttrain-auc:0.985517\tval-auc:0.961025\n",
      "[800]\ttrain-auc:0.987012\tval-auc:0.962098\n",
      "[850]\ttrain-auc:0.988224\tval-auc:0.962862\n",
      "[900]\ttrain-auc:0.989501\tval-auc:0.963831\n",
      "[950]\ttrain-auc:0.990582\tval-auc:0.964865\n",
      "[1000]\ttrain-auc:0.991479\tval-auc:0.965577\n",
      "[1050]\ttrain-auc:0.992334\tval-auc:0.966296\n",
      "[1100]\ttrain-auc:0.993151\tval-auc:0.96685\n",
      "[1150]\ttrain-auc:0.993733\tval-auc:0.967384\n",
      "[1200]\ttrain-auc:0.994309\tval-auc:0.967793\n",
      "[1250]\ttrain-auc:0.994817\tval-auc:0.968265\n",
      "[1300]\ttrain-auc:0.995359\tval-auc:0.968985\n",
      "[1350]\ttrain-auc:0.99579\tval-auc:0.969405\n",
      "[1400]\ttrain-auc:0.996173\tval-auc:0.969819\n",
      "[1450]\ttrain-auc:0.996492\tval-auc:0.97018\n",
      "[1500]\ttrain-auc:0.996805\tval-auc:0.970676\n",
      "[1550]\ttrain-auc:0.997138\tval-auc:0.970927\n",
      "[1600]\ttrain-auc:0.997421\tval-auc:0.971187\n",
      "[1650]\ttrain-auc:0.997651\tval-auc:0.971352\n",
      "[1700]\ttrain-auc:0.997856\tval-auc:0.97163\n",
      "[1750]\ttrain-auc:0.998065\tval-auc:0.971761\n",
      "[1800]\ttrain-auc:0.998247\tval-auc:0.971969\n",
      "[1850]\ttrain-auc:0.998382\tval-auc:0.972212\n",
      "[1900]\ttrain-auc:0.998528\tval-auc:0.972469\n",
      "[1950]\ttrain-auc:0.998667\tval-auc:0.972586\n",
      "[1999]\ttrain-auc:0.9988\tval-auc:0.973018\n",
      "[0]\ttrain-auc:0.781284\tval-auc:0.782337\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.902596\tval-auc:0.8955\n",
      "[100]\ttrain-auc:0.92882\tval-auc:0.917748\n",
      "[150]\ttrain-auc:0.941047\tval-auc:0.927889\n",
      "[200]\ttrain-auc:0.949246\tval-auc:0.93417\n",
      "[250]\ttrain-auc:0.955505\tval-auc:0.939301\n",
      "[300]\ttrain-auc:0.961195\tval-auc:0.943751\n",
      "[350]\ttrain-auc:0.965513\tval-auc:0.946745\n",
      "[400]\ttrain-auc:0.969044\tval-auc:0.949087\n",
      "[450]\ttrain-auc:0.972337\tval-auc:0.951401\n",
      "[500]\ttrain-auc:0.975416\tval-auc:0.953544\n",
      "[550]\ttrain-auc:0.977984\tval-auc:0.955483\n",
      "[600]\ttrain-auc:0.980297\tval-auc:0.957541\n",
      "[650]\ttrain-auc:0.982162\tval-auc:0.958939\n",
      "[700]\ttrain-auc:0.98411\tval-auc:0.960232\n",
      "[750]\ttrain-auc:0.985528\tval-auc:0.961287\n",
      "[800]\ttrain-auc:0.986912\tval-auc:0.962441\n",
      "[850]\ttrain-auc:0.988254\tval-auc:0.963288\n",
      "[900]\ttrain-auc:0.989464\tval-auc:0.964234\n",
      "[950]\ttrain-auc:0.99045\tval-auc:0.964853\n",
      "[1000]\ttrain-auc:0.991356\tval-auc:0.965635\n",
      "[1050]\ttrain-auc:0.992146\tval-auc:0.96625\n",
      "[1100]\ttrain-auc:0.992883\tval-auc:0.966799\n",
      "[1150]\ttrain-auc:0.993593\tval-auc:0.967374\n",
      "[1200]\ttrain-auc:0.994193\tval-auc:0.967927\n",
      "[1250]\ttrain-auc:0.994675\tval-auc:0.968235\n",
      "[1300]\ttrain-auc:0.995219\tval-auc:0.968696\n",
      "[1350]\ttrain-auc:0.995737\tval-auc:0.969289\n",
      "[1400]\ttrain-auc:0.996137\tval-auc:0.969705\n",
      "[1450]\ttrain-auc:0.996514\tval-auc:0.970247\n",
      "[1500]\ttrain-auc:0.996913\tval-auc:0.970557\n",
      "[1550]\ttrain-auc:0.99721\tval-auc:0.970746\n",
      "[1600]\ttrain-auc:0.997477\tval-auc:0.971036\n",
      "[1650]\ttrain-auc:0.997711\tval-auc:0.971339\n",
      "[1700]\ttrain-auc:0.99793\tval-auc:0.971624\n",
      "[1750]\ttrain-auc:0.99811\tval-auc:0.971823\n",
      "[1800]\ttrain-auc:0.998268\tval-auc:0.971936\n",
      "[1850]\ttrain-auc:0.998454\tval-auc:0.972347\n",
      "[1900]\ttrain-auc:0.998608\tval-auc:0.972546\n",
      "[1950]\ttrain-auc:0.998747\tval-auc:0.972633\n",
      "[1999]\ttrain-auc:0.998883\tval-auc:0.972801\n",
      "[0]\ttrain-auc:0.791115\tval-auc:0.793169\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.902538\tval-auc:0.895598\n",
      "[100]\ttrain-auc:0.928882\tval-auc:0.918832\n",
      "[150]\ttrain-auc:0.940953\tval-auc:0.929317\n",
      "[200]\ttrain-auc:0.949377\tval-auc:0.935445\n",
      "[250]\ttrain-auc:0.954885\tval-auc:0.939317\n",
      "[300]\ttrain-auc:0.959871\tval-auc:0.942758\n",
      "[350]\ttrain-auc:0.964942\tval-auc:0.946225\n",
      "[400]\ttrain-auc:0.969383\tval-auc:0.949368\n",
      "[450]\ttrain-auc:0.972742\tval-auc:0.951908\n",
      "[500]\ttrain-auc:0.975647\tval-auc:0.954011\n",
      "[550]\ttrain-auc:0.978146\tval-auc:0.955696\n",
      "[600]\ttrain-auc:0.980282\tval-auc:0.957177\n",
      "[650]\ttrain-auc:0.982247\tval-auc:0.958582\n",
      "[700]\ttrain-auc:0.984058\tval-auc:0.960087\n",
      "[750]\ttrain-auc:0.985763\tval-auc:0.961286\n",
      "[800]\ttrain-auc:0.98718\tval-auc:0.962463\n",
      "[850]\ttrain-auc:0.988253\tval-auc:0.963035\n",
      "[900]\ttrain-auc:0.989355\tval-auc:0.964113\n",
      "[950]\ttrain-auc:0.99049\tval-auc:0.964925\n",
      "[1000]\ttrain-auc:0.991209\tval-auc:0.965553\n",
      "[1050]\ttrain-auc:0.99198\tval-auc:0.965975\n",
      "[1100]\ttrain-auc:0.992825\tval-auc:0.966856\n",
      "[1150]\ttrain-auc:0.993553\tval-auc:0.967417\n",
      "[1200]\ttrain-auc:0.99422\tval-auc:0.968061\n",
      "[1250]\ttrain-auc:0.994821\tval-auc:0.968525\n",
      "[1300]\ttrain-auc:0.995277\tval-auc:0.969149\n",
      "[1350]\ttrain-auc:0.995705\tval-auc:0.969624\n",
      "[1400]\ttrain-auc:0.996082\tval-auc:0.969941\n",
      "[1450]\ttrain-auc:0.996396\tval-auc:0.970223\n",
      "[1500]\ttrain-auc:0.996706\tval-auc:0.970509\n",
      "[1550]\ttrain-auc:0.997087\tval-auc:0.970943\n",
      "[1600]\ttrain-auc:0.99739\tval-auc:0.971359\n",
      "[1650]\ttrain-auc:0.997624\tval-auc:0.971671\n",
      "[1700]\ttrain-auc:0.997824\tval-auc:0.971942\n",
      "[1750]\ttrain-auc:0.998047\tval-auc:0.972183\n",
      "[1800]\ttrain-auc:0.998247\tval-auc:0.972342\n",
      "[1850]\ttrain-auc:0.998406\tval-auc:0.972551\n",
      "[1900]\ttrain-auc:0.998568\tval-auc:0.972648\n",
      "[1950]\ttrain-auc:0.998715\tval-auc:0.972826\n",
      "[1999]\ttrain-auc:0.998847\tval-auc:0.973036\n",
      "0.0\n",
      "0.9999977946281433\n",
      "9.870897e-09\n",
      "0.19999924\n",
      "[0]\ttrain-auc:0.778711\tval-auc:0.781614\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.901847\tval-auc:0.900841\n",
      "[100]\ttrain-auc:0.930397\tval-auc:0.922919\n",
      "[150]\ttrain-auc:0.941152\tval-auc:0.930941\n",
      "[200]\ttrain-auc:0.949149\tval-auc:0.937229\n",
      "[250]\ttrain-auc:0.955487\tval-auc:0.941796\n",
      "[300]\ttrain-auc:0.960714\tval-auc:0.945774\n",
      "[350]\ttrain-auc:0.964248\tval-auc:0.948437\n",
      "[400]\ttrain-auc:0.968033\tval-auc:0.951447\n",
      "[450]\ttrain-auc:0.971356\tval-auc:0.953961\n",
      "[500]\ttrain-auc:0.974268\tval-auc:0.955954\n",
      "[550]\ttrain-auc:0.977001\tval-auc:0.958126\n",
      "[600]\ttrain-auc:0.979341\tval-auc:0.959616\n",
      "[650]\ttrain-auc:0.981458\tval-auc:0.961005\n",
      "[700]\ttrain-auc:0.983362\tval-auc:0.962441\n",
      "[750]\ttrain-auc:0.984939\tval-auc:0.963682\n",
      "[800]\ttrain-auc:0.986307\tval-auc:0.964608\n",
      "[850]\ttrain-auc:0.987508\tval-auc:0.965238\n",
      "[900]\ttrain-auc:0.988778\tval-auc:0.966328\n",
      "[950]\ttrain-auc:0.989824\tval-auc:0.966938\n",
      "[1000]\ttrain-auc:0.990723\tval-auc:0.967428\n",
      "[1050]\ttrain-auc:0.991678\tval-auc:0.968314\n",
      "[1100]\ttrain-auc:0.992559\tval-auc:0.96901\n",
      "[1150]\ttrain-auc:0.993338\tval-auc:0.969512\n",
      "[1200]\ttrain-auc:0.99398\tval-auc:0.97007\n",
      "[1250]\ttrain-auc:0.994497\tval-auc:0.970495\n",
      "[1300]\ttrain-auc:0.995015\tval-auc:0.970915\n",
      "[1350]\ttrain-auc:0.995479\tval-auc:0.971248\n",
      "[1400]\ttrain-auc:0.995905\tval-auc:0.971441\n",
      "[1450]\ttrain-auc:0.996246\tval-auc:0.971814\n",
      "[1500]\ttrain-auc:0.996628\tval-auc:0.972238\n",
      "[1550]\ttrain-auc:0.996943\tval-auc:0.972588\n",
      "[1600]\ttrain-auc:0.997249\tval-auc:0.972859\n",
      "[1650]\ttrain-auc:0.997515\tval-auc:0.973094\n",
      "[1700]\ttrain-auc:0.997736\tval-auc:0.973287\n",
      "[1750]\ttrain-auc:0.997969\tval-auc:0.973431\n",
      "[1800]\ttrain-auc:0.998155\tval-auc:0.973645\n",
      "[1850]\ttrain-auc:0.998343\tval-auc:0.973876\n",
      "[1900]\ttrain-auc:0.998528\tval-auc:0.97406\n",
      "[1950]\ttrain-auc:0.998662\tval-auc:0.97428\n",
      "[1999]\ttrain-auc:0.998789\tval-auc:0.97436\n",
      "[0]\ttrain-auc:0.783589\tval-auc:0.784194\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.900731\tval-auc:0.900202\n",
      "[100]\ttrain-auc:0.929675\tval-auc:0.922015\n",
      "[150]\ttrain-auc:0.94136\tval-auc:0.930614\n",
      "[200]\ttrain-auc:0.949402\tval-auc:0.937208\n",
      "[250]\ttrain-auc:0.95526\tval-auc:0.941372\n",
      "[300]\ttrain-auc:0.960134\tval-auc:0.945366\n",
      "[350]\ttrain-auc:0.964575\tval-auc:0.948731\n",
      "[400]\ttrain-auc:0.968791\tval-auc:0.952036\n",
      "[450]\ttrain-auc:0.972027\tval-auc:0.954289\n",
      "[500]\ttrain-auc:0.97481\tval-auc:0.956388\n",
      "[550]\ttrain-auc:0.977242\tval-auc:0.958158\n",
      "[600]\ttrain-auc:0.979625\tval-auc:0.959755\n",
      "[650]\ttrain-auc:0.981301\tval-auc:0.960925\n",
      "[700]\ttrain-auc:0.983089\tval-auc:0.962171\n",
      "[750]\ttrain-auc:0.98468\tval-auc:0.96352\n",
      "[800]\ttrain-auc:0.986261\tval-auc:0.964776\n",
      "[850]\ttrain-auc:0.987593\tval-auc:0.965701\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "cv_scores = []\n",
    "pred_test_f = 0\n",
    "pred_train = np.zeros(train.shape[0])\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=99)\n",
    "for build_index, val_index in kf.split(x_train, y_train):\n",
    "    x_build = x_train.iloc[build_index]\n",
    "    y_build = y_train.iloc[build_index]\n",
    "    x_val = x_train.iloc[val_index]\n",
    "    y_val = y_train.iloc[val_index]\n",
    "    pred_val = 0\n",
    "    pred_test = 0\n",
    "    n_models = 0.\n",
    "    \n",
    "    model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 10999973) \n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "    \n",
    "    model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 99) \n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "\n",
    "    \n",
    "    model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 90351) \n",
    "    pred_val += pred_v\n",
    "    pred_test += pred_t\n",
    "    n_models += 1\n",
    "    \n",
    "    pred_val /= n_models\n",
    "    pred_test /= n_models\n",
    "\n",
    "    \n",
    "    pred_train[val_index] = pred_val\n",
    "    print(min(pred_train)),print(max(pred_train))\n",
    "    pred_test_f += pred_test / n_splits\n",
    "    print(min(pred_test_f)),print(max(pred_test_f))\n",
    "    #xgb_preds_lst.append(clf_xgb.predict(dtest))  \n",
    "    #models.append(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_test ,columns = ['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl = pd.concat([td, pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv1_data = pd.concat([train['TransactionID'],pd.DataFrame(pred_train ,columns = ['v1pred'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl.to_csv(\"fraud_preds_15xgb5f2k.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv1_data.to_csv(\"predv1_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "fnl.to_csv('fnl_part4.csv',index = False)\n",
    "files.download('fnl_part4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
