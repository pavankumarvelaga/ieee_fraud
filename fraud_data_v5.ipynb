{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()\n",
    "import bokeh as bh\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from glob import glob\n",
    "import re\n",
    "from math import ceil\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold,KFold,StratifiedKFold,train_test_split\n",
    "import random\n",
    "import operator\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import datetime \n",
    "import fastai.tabular as ft\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('train_identity.csv')\n",
    "train_trans = pd.read_csv('train_transaction.csv')\n",
    "train_df = train_trans.merge(train_id,how='left',on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = pd.read_csv('test_identity.csv')\n",
    "test_trans = pd.read_csv('test_transaction.csv')\n",
    "test_df = test_trans.merge(test_id,how='left',on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_id,train_trans,test_id,test_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prdm1 = pd.read_csv('predv1_data.csv')\n",
    "# prdm1 = prdm1[prdm1['v1pred'].notnull()]\n",
    "# prdm2 = pd.read_csv('predv1_data_v2ft.csv')\n",
    "# prdm2 = prdm2[prdm2['v1pred'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array(prdm1['v1pred'])\n",
    "# b = np.array(prdm2['v1pred'])\n",
    "# c = np.array(train_df['TransactionID'])\n",
    "# pred = pd.DataFrame({'TransactionID':c, 'isFraudpred1':a,'isFraudpred2':b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = pd.read_csv('fraud_preds_15xgb5f.csv')\n",
    "# t2 = pd.read_csv('fraud_preds_15xgb5f2k_v2ft.csv')\n",
    "# t3 = t1.merge(t2,how='left',on=['TransactionID'])\n",
    "# t3.columns = ['TransactionID','isFraudpred1','isFraudpred2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.merge(pred,how='left',on=['TransactionID'])\n",
    "# test_df = test_df.merge(t3,how='left',on=['TransactionID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aim.com',\n",
       " 'anonymous.com',\n",
       " 'aol.com',\n",
       " 'att.net',\n",
       " 'bellsouth.net',\n",
       " 'cableone.net',\n",
       " 'centurylink.net',\n",
       " 'cfl.rr.com',\n",
       " 'charter.net',\n",
       " 'comcast.net',\n",
       " 'cox.net',\n",
       " 'earthlink.net',\n",
       " 'embarqmail.com',\n",
       " 'frontier.com',\n",
       " 'frontiernet.net',\n",
       " 'gmail',\n",
       " 'gmail.com',\n",
       " 'gmx.de',\n",
       " 'hotmail.co.uk',\n",
       " 'hotmail.com',\n",
       " 'hotmail.de',\n",
       " 'hotmail.es',\n",
       " 'hotmail.fr',\n",
       " 'icloud.com',\n",
       " 'juno.com',\n",
       " 'live.com',\n",
       " 'live.com.mx',\n",
       " 'live.fr',\n",
       " 'mac.com',\n",
       " 'mail.com',\n",
       " 'me.com',\n",
       " 'msn.com',\n",
       " nan,\n",
       " 'netzero.com',\n",
       " 'netzero.net',\n",
       " 'optonline.net',\n",
       " 'outlook.com',\n",
       " 'outlook.es',\n",
       " 'prodigy.net.mx',\n",
       " 'protonmail.com',\n",
       " 'ptd.net',\n",
       " 'q.com',\n",
       " 'roadrunner.com',\n",
       " 'rocketmail.com',\n",
       " 'sbcglobal.net',\n",
       " 'sc.rr.com',\n",
       " 'servicios-ta.com',\n",
       " 'suddenlink.net',\n",
       " 'twc.com',\n",
       " 'verizon.net',\n",
       " 'web.de',\n",
       " 'windstream.net',\n",
       " 'yahoo.co.jp',\n",
       " 'yahoo.co.uk',\n",
       " 'yahoo.com',\n",
       " 'yahoo.com.mx',\n",
       " 'yahoo.de',\n",
       " 'yahoo.es',\n",
       " 'yahoo.fr',\n",
       " 'ymail.com'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "set(train_df['P_emaildomain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum',\n",
    "          'scranton.edu': 'other', 'netzero.net': 'other',\n",
    "          'optonline.net': 'other', 'comcast.net': 'other', \n",
    "          'cfl.rr.com': 'other', 'sc.rr.com': 'other',\n",
    "          'suddenlink.net': 'other', 'windstream.net': 'other',\n",
    "          'gmx.de': 'other', 'earthlink.net': 'other', \n",
    "          'servicios-ta.com': 'other', 'bellsouth.net': 'other', \n",
    "          'web.de': 'other', 'mail.com': 'other',\n",
    "          'cableone.net': 'other', 'roadrunner.com': 'other', \n",
    "          'protonmail.com': 'other', 'anonymous.com': 'other',\n",
    "          'juno.com': 'other', 'ptd.net': 'other',\n",
    "          'netzero.com': 'other', 'cox.net': 'other', \n",
    "          'hotmail.co.uk': 'microsoft', \n",
    "          'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', \n",
    "          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', \n",
    "          'live.com': 'microsoft', 'aim.com': 'aol',\n",
    "          'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n",
    "          'gmail.com': 'google', 'me.com': 'apple', \n",
    "          'hotmail.com': 'microsoft',  \n",
    "          'hotmail.fr': 'microsoft',\n",
    "          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', \n",
    "          'yahoo.de': 'yahoo', \n",
    "          'live.fr': 'microsoft', 'verizon.net': 'yahoo', \n",
    "          'msn.com': 'microsoft', 'q.com': 'centurylink',\n",
    "          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', \n",
    "           'rocketmail.com': 'yahoo', \n",
    "          'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n",
    "          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', \n",
    "          'embarqmail.com': 'centurylink', \n",
    "          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo',\n",
    "          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft',\n",
    "           'aol.com': 'aol', 'icloud.com': 'apple'}\n",
    "\n",
    "us_emails = ['gmail', 'net', 'edu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    train_df[c + '_bin'] = train_df[c].map(emails)\n",
    "    test_df[c + '_bin'] = test_df[c].map(emails)\n",
    "    \n",
    "    train_df[c + '_suffix'] = train_df[c].map(lambda x: str(x).split('.')[-1])\n",
    "    test_df[c + '_suffix'] = test_df[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    train_df[c + '_suffix'] = train_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    test_df[c + '_suffix'] = test_df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corret_card_id(x): \n",
    "    x=x.replace('.0','')\n",
    "    x=x.replace('-999','nan')\n",
    "    return x\n",
    "\n",
    "def define_indexes(df):\n",
    "    \n",
    "    # create date column\n",
    "    START_DATE = '2017-12-01'\n",
    "    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "    df['TransactionDT'] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "    \n",
    "    df['year'] = df['TransactionDT'].dt.year\n",
    "    df['month'] = df['TransactionDT'].dt.month\n",
    "    df['dow'] = df['TransactionDT'].dt.dayofweek\n",
    "    df['hour'] = df['TransactionDT'].dt.hour\n",
    "    df['day'] = df['TransactionDT'].dt.day\n",
    "   \n",
    "    # create card ID \n",
    "    cards_cols= ['card1', 'card2', 'card3', 'card5']\n",
    "    for card in cards_cols: \n",
    "        if '1' in card: \n",
    "            df['card_id']= df[card].map(str)\n",
    "        else : \n",
    "            df['card_id']+= ' '+df[card].map(str)\n",
    "    \n",
    "    # small correction of the Card_ID\n",
    "    df['card_id']=df['card_id'].apply(corret_card_id)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = define_indexes(train_df)\n",
    "test_df = define_indexes(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Trans_min_mean'] = train_df['TransactionAmt'] - train_df['TransactionAmt'].mean()\n",
    "train_df['Trans_min_std'] = train_df['Trans_min_mean'] / train_df['TransactionAmt'].std()\n",
    "test_df['Trans_min_mean'] = test_df['TransactionAmt'] - test_df['TransactionAmt'].mean()\n",
    "test_df['Trans_min_std'] = test_df['Trans_min_mean'] / test_df['TransactionAmt'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_to_mean_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_mean_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train_df['TransactionAmt_to_std_card1'] = train_df['TransactionAmt'] / train_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train_df['TransactionAmt_to_std_card4'] = train_df['TransactionAmt'] / train_df.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test_df['TransactionAmt_to_mean_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_mean_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test_df['TransactionAmt_to_std_card1'] = test_df['TransactionAmt'] / test_df.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test_df['TransactionAmt_to_std_card4'] = test_df['TransactionAmt'] / test_df.groupby(['card4'])['TransactionAmt'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['first_value_card1'] = train_df['card1'].astype(str).str[0:1].astype(float)\n",
    "train_df['two_value_card1'] = train_df['card1'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "test_df['first_value_card1'] = test_df['card1'].astype(str).str[0:1].astype(float)\n",
    "test_df['two_value_card1'] = test_df['card1'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "train_df['card2'] = train_df['card2'].fillna(0)\n",
    "train_df['first_value_card2'] = train_df['card2'].astype(str).str[0:1].astype(float)\n",
    "train_df['two_value_card2'] = train_df['card2'].astype(str).str[0:2].astype(float)\n",
    "\n",
    "test_df['card2'] = test_df['card2'].fillna(0)\n",
    "test_df['first_value_card2'] = test_df['card2'].astype(str).str[0:1].astype(float)\n",
    "test_df['two_value_card2'] = test_df['card2'].astype(str).str[0:2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train_df.columns)\n",
    "for i in ['isFraud','TransactionDT']:\n",
    "    cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mv = missing_data(train_df)\n",
    "test_mv = missing_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_exp_lst = []\n",
    "for i in cols:\n",
    "    if train_mv[i]['Percent'] > 90 and test_mv[i]['Percent'] >90:\n",
    "        col_exp_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col_exp_lst:\n",
    "    cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TransactionAmt_decimal'] = ((train_df['TransactionAmt'] - train_df['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test_df['TransactionAmt_decimal'] = ((test_df['TransactionAmt'] - test_df['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "# Count encoding for card1 feature. \n",
    "# Explained in this kernel: https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\n",
    "train_df['card1_count_full'] = train_df['card1'].map(pd.concat([train_df['card1'], test_df['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "test_df['card1_count_full'] = test_df['card1'].map(pd.concat([train_df['card1'], test_df['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-featur\n",
    "\n",
    "# Some arbitrary features interaction\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train_df[feature] = train_df[f1].astype(str) + '_' + train_df[f2].astype(str)\n",
    "    test_df[feature] = test_df[f1].astype(str) + '_' + test_df[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train_df[feature].astype(str).values) + list(test_df[feature].astype(str).values))\n",
    "    train_df[feature] = le.transform(list(train_df[feature].astype(str).values))\n",
    "    test_df[feature] = le.transform(list(test_df[feature].astype(str).values))\n",
    "    \n",
    "for feature in ['id_34', 'id_36']:\n",
    "    if feature in cols:\n",
    "        # Count encoded for both train and test\n",
    "        train_df[feature + '_count_full'] = train_df[feature].map(pd.concat([train_df[feature], test_df[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        test_df[feature + '_count_full'] = test_df[feature].map(pd.concat([train_df[feature], test_df[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "        \n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_35', 'id_36']:\n",
    "    if feature in cols:\n",
    "        # Count encoded separately for train and test\n",
    "        train_df[feature + '_count_dist'] = train_df[feature].map(train_df[feature].value_counts(dropna=False))\n",
    "        test_df[feature + '_count_dist'] = test_df[feature].map(test_df[feature].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist2\n",
      "id_07\n",
      "id_08\n",
      "id_21\n",
      "id_22\n",
      "id_23\n",
      "id_24\n",
      "id_25\n",
      "id_26\n",
      "id_27\n",
      "isFraud\n",
      "TransactionDT\n"
     ]
    }
   ],
   "source": [
    "cols_for_model = list(train_df.columns)\n",
    "col_exp_lst.extend(['isFraud','TransactionDT'])\n",
    "for i in col_exp_lst:\n",
    "    print(i)\n",
    "    cols_for_model.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD-object\n",
      "card4-object\n",
      "card6-object\n",
      "P_emaildomain-object\n",
      "R_emaildomain-object\n",
      "M1-object\n",
      "M2-object\n",
      "M3-object\n",
      "M4-object\n",
      "M5-object\n",
      "M6-object\n",
      "M7-object\n",
      "M8-object\n",
      "M9-object\n",
      "id_12-object\n",
      "id_15-object\n",
      "id_16-object\n",
      "id_28-object\n",
      "id_29-object\n",
      "id_30-object\n",
      "id_31-object\n",
      "id_33-object\n",
      "id_34-object\n",
      "id_35-object\n",
      "id_36-object\n",
      "id_37-object\n",
      "id_38-object\n",
      "DeviceType-object\n",
      "DeviceInfo-object\n",
      "P_emaildomain_bin-object\n",
      "P_emaildomain_suffix-object\n",
      "R_emaildomain_bin-object\n",
      "R_emaildomain_suffix-object\n",
      "card_id-object\n"
     ]
    }
   ],
   "source": [
    "for f in cols_for_model:\n",
    "    if train_df[f].dtype=='object':\n",
    "        print(f+\"-\"+str(train_df[f].dtype))\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        test_df[f] = lbl.transform(list(test_df[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-12-02 00:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_df['TransactionDT']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-06-01 23:58:51')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_df['TransactionDT']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_df = train_df[train_df['TransactionDT'] < datetime.datetime.strptime('2018-04-01', '%Y-%m-%d')].reset_index()\n",
    "val_df = train_df[train_df['TransactionDT'] >= datetime.datetime.strptime('2018-04-01', '%Y-%m-%d')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsMeter():    \n",
    "    def __init__(self, y_true, y_pred, threshold):\n",
    "        self.y_true = y_true        \n",
    "        self.y_pred = y_pred        \n",
    "        self.thresh = threshold            \n",
    "    \n",
    "    def fit(self):        \n",
    "        metrics = {}        \n",
    "        metrics['auc'] = roc_auc_score(self.y_true, self.y_pred)                \n",
    "        self.y_pred = [1 if x > self.thresh else 0 for x in self.y_pred]        \n",
    "        metrics['f1'] = f1_score(self.y_true, self.y_pred,average = 'macro')        \n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_true, self.y_pred).ravel()                \n",
    "        metrics['sensitivity/recall'] = tp / (tp+fn)\n",
    "        metrics['precision'] = tp / (tp+fp)\n",
    "        metrics[\"accuracy\"] = (tp + tn) / (tp + fp + fn + tn)\n",
    "        metrics['specificity'] = tn / (tn+fp)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunXGB(x_build,x_val,y_build,y_val,dtest,seed):\n",
    "    dbuild = xgb.DMatrix(x_build,y_build)\n",
    "    dval = xgb.DMatrix(x_val,y_val)\n",
    "    watchlist = [(dbuild, 'train'), (dval, 'val')]\n",
    "    params = {'objective': 'binary:logistic',\n",
    "              'booster': 'gbtree',\n",
    "              'eval_metric': 'auc',\n",
    "              'nthread': 96,\n",
    "              'max_depth': 7,\n",
    "              #'learning_rate': 0.009\n",
    "              'subsample': 0.8,\n",
    "              'min_child_weight': 1,\n",
    "              \"colsample_bytree\": 0.9,\n",
    "              'eta': 0.08,\n",
    "              'verbose_eval': True,\n",
    "              'silent':1,\n",
    "              'seed': seed\n",
    "              }\n",
    "    clf_xgb = xgb.train(params, dbuild, num_boost_round=1000, verbose_eval=50, early_stopping_rounds=30, evals=watchlist)\n",
    "    pred_val = clf_xgb.predict(dval, ntree_limit=clf_xgb.best_iteration)\n",
    "    pred_t = clf_xgb.predict(dtest, ntree_limit=clf_xgb.best_iteration)\n",
    "    return(clf_xgb,pred_val,pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.803663\tval-auc:0.788866\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 30 rounds.\n",
      "[50]\ttrain-auc:0.919842\tval-auc:0.880019\n",
      "[100]\ttrain-auc:0.952389\tval-auc:0.903687\n",
      "[150]\ttrain-auc:0.964137\tval-auc:0.909601\n",
      "[200]\ttrain-auc:0.970759\tval-auc:0.91359\n",
      "Stopping. Best iteration:\n",
      "[200]\ttrain-auc:0.970759\tval-auc:0.91359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test_df[cols_for_model].iloc[:])\n",
    "model1,pred_v1,pred_t1 = RunXGB(build_df[cols_for_model].iloc[:],val_df[cols_for_model].iloc[:],\n",
    "build_df['isFraud'].iloc[:],val_df['isFraud'].iloc[:],dtest,seed = 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.reset_index(drop =True)\n",
    "x_train = train[cols_for_model]\n",
    "y_train = train['isFraud']\n",
    "dtest = xgb.DMatrix(test_df[cols_for_model].iloc[:])\n",
    "td = test_df['TransactionID'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits = 5\n",
    "# cv_scores = []\n",
    "# pred_test_f = 0\n",
    "# pred_train = np.zeros(train.shape[0])\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=99)\n",
    "# for build_index, val_index in kf.split(x_train, y_train):\n",
    "#     x_build = x_train.iloc[build_index]\n",
    "#     y_build = y_train.iloc[build_index]\n",
    "#     x_val = x_train.iloc[val_index]\n",
    "#     y_val = y_train.iloc[val_index]\n",
    "#     pred_val = 0\n",
    "#     pred_test = 0\n",
    "#     n_models = 0.\n",
    "    \n",
    "#     model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 10999973) \n",
    "#     pred_val += pred_v\n",
    "#     pred_test += pred_t\n",
    "#     n_models += 1\n",
    "    \n",
    "#     model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 99) \n",
    "#     pred_val += pred_v\n",
    "#     pred_test += pred_t\n",
    "#     n_models += 1\n",
    "\n",
    "    \n",
    "#     model,pred_v,pred_t = RunXGB(x_build,x_val,y_build,y_val,dtest,seed = 90351) \n",
    "#     pred_val += pred_v\n",
    "#     pred_test += pred_t\n",
    "#     n_models += 1\n",
    "    \n",
    "#     pred_val /= n_models\n",
    "#     pred_test /= n_models\n",
    "\n",
    "    \n",
    "#     pred_train[val_index] = pred_val\n",
    "#     print(min(pred_train)),print(max(pred_train))\n",
    "#     pred_test_f += pred_test / n_splits\n",
    "#     print(min(pred_test_f)),print(max(pred_test_f))\n",
    "#     #xgb_preds_lst.append(clf_xgb.predict(dtest))  \n",
    "#     #models.append(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred_t1 ,columns = ['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl = pd.concat([td, pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predv1_data = pd.concat([train['TransactionID'],pd.DataFrame(pred_train ,columns = ['v1pred'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl.to_csv(\"fraud_preds_15xgb5f2k_tssp_vx3.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predv1_data.to_csv(\"predv1_data_v2ft.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "fnl.to_csv('fnl_part4.csv',index = False)\n",
    "files.download('fnl_part4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
